# ğŸ—ï¸ Project Alpha-RL: Architecture Documentation

> **An Informed RL Agent for Portfolio Optimization**
>
> This document provides a comprehensive technical overview of the project architecture, component interactions, and implementation details.

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#1-project-overview)
2. [System Architecture](#2-system-architecture)
3. [Component Deep Dive](#3-component-deep-dive)
4. [Data Flow](#4-data-flow)
5. [Directory Structure](#5-directory-structure)
6. [Training Pipeline](#6-training-pipeline)
7. [Configuration](#7-configuration)
8. [Future Roadmap](#8-future-roadmap)

---

## 1. Project Overview

### 1.1 Mission

Build an autonomous **Reinforcement Learning (RL) agent** that intelligently manages a stock portfolio to maximize **risk-adjusted returns (Sharpe Ratio)**.

### 1.2 Core Innovation

Unlike traditional trading bots that only analyze price data, our agent uses a **"Super-State"** that combines:

| Component | Input | Output | Purpose |
|-----------|-------|--------|---------|
| **DeepAR** | Historical prices | Probability distribution (Î¼, Ïƒ) | Uncertainty-aware forecasting |
| **FinBERT/NLP** | Financial news | Sentiment vector | Market mood detection |
| **FRED API** | Economic indicators | Macro vector | Regime awareness |
| **PPO Agent** | All of the above | Portfolio weights | Decision making |

### 1.3 Key Differentiators

1. **Probabilistic Forecasting**: Not just "price will be $150" but "90% chance between $145-$155"
2. **Regime Awareness**: Agent knows if we're in a bull market, recession, or crisis
3. **ReST Training**: Novel "Grow/Improve" methodology adapted from language models

---

## 2. System Architecture

### 2.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PPO AGENT (Brain)                           â”‚
â”‚                     Outputs: Portfolio Weights                      â”‚
â”‚                   [AAPL: 0.3, MSFT: 0.5, CASH: 0.2]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–²
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   DeepAR      â”‚ â”‚  FinBERT  â”‚ â”‚  FRED API     â”‚
            â”‚  (Forecaster) â”‚ â”‚   (NLP)   â”‚ â”‚ (Macro Data)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–²               â–²               â–²
                    â”‚               â”‚               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Price History â”‚ â”‚   News    â”‚ â”‚ Fed Rates,    â”‚
            â”‚ OHLCV Data    â”‚ â”‚  Articles â”‚ â”‚ VIX, Yields   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Data Flow Diagram

```
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                      DATA SOURCES                            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                   â”‚                   â”‚
                    â–¼                   â–¼                   â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Bloomberg/Yahoo    â”‚ â”‚ Financial News  â”‚ â”‚ Federal Reserve   â”‚
       â”‚ Price Data         â”‚ â”‚ APIs            â”‚ â”‚ (FRED API)        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                   â”‚                   â”‚
                    â–¼                   â–¼                   â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ build_deepar_      â”‚ â”‚ FinBERT         â”‚ â”‚ fred_data.py      â”‚
       â”‚ dataset.py         â”‚ â”‚ Pipeline        â”‚ â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                   â”‚                   â”‚
                    â–¼                   â–¼                   â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ deepar_dataset.csv â”‚ â”‚ Sentiment       â”‚ â”‚ fred_macro_data   â”‚
       â”‚ (Engineered        â”‚ â”‚ Scores          â”‚ â”‚ .csv              â”‚
       â”‚  Features)         â”‚ â”‚                 â”‚ â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                   â”‚                   â”‚
                    â–¼                   â–¼                   â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                    SUPER-STATE VECTOR                        â”‚
       â”‚  [Forecast Î¼, Ïƒ] + [Sentiment] + [Macro: VIX, Yield, Rate]  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                      PPO AGENT                               â”‚
       â”‚              Proximal Policy Optimization                    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                   PORTFOLIO WEIGHTS                          â”‚
       â”‚           Action: Rebalance to new allocations               â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Component Deep Dive

### 3.1 DeepAR Forecaster (`deepAR/`)

**Purpose**: Predict the probability distribution of future stock returns.

#### Architecture

```
Input: [Price History, Dynamic Features, Series Embedding]
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  LSTM Network  â”‚
                   â”‚  (2 layers,    â”‚
                   â”‚   64 hidden)   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Gaussian Head  â”‚
                   â”‚   Î¼ layer      â”‚
                   â”‚   Ïƒ layer      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
            Output: (mean, variance) distribution
```

#### Key Files

| File | Purpose |
|------|---------|
| `deepAR/model.py` | DeepARModel class with LSTM + Gaussian output |
| `deepAR/train_deepar.py` | Training pipeline with early stopping |
| `deepAR/bloomberg-data-extraction/build_deepar_dataset.py` | Feature engineering |

#### Features Engineered

| Feature | Formula | Purpose |
|---------|---------|---------|
| `log_return` | ln(Pâ‚œ / Pâ‚œâ‚‹â‚) | Stationarity |
| `roll_vol_10` | std(returns, 10d) | Volatility signal |
| `ret_5d` | (Pâ‚œ - Pâ‚œâ‚‹â‚…) / Pâ‚œâ‚‹â‚… | Short-term momentum |
| `ret_20d` | (Pâ‚œ - Pâ‚œâ‚‹â‚‚â‚€) / Pâ‚œâ‚‹â‚‚â‚€ | Medium-term momentum |
| `zvol` | (Vol - Î¼) / Ïƒ | Volume anomaly |

#### Training Configuration

```python
DEFAULT_CONFIG = {
    "hidden_size": 64,        # LSTM hidden units
    "num_layers": 2,          # LSTM depth
    "dropout": 0.1,           # Regularization
    "context_length": 60,     # 60 days of history
    "prediction_length": 5,   # Predict 5 days ahead
    "batch_size": 64,
    "learning_rate": 1e-3,
    "patience": 10,           # Early stopping
}
```

---

### 3.2 FRED Macro Monitor (`fred_data_extraction/`)

**Purpose**: Track economic regime indicators from the Federal Reserve.

#### Key Indicators

| Indicator | FRED Code | Interpretation |
|-----------|-----------|----------------|
| **Yield Curve** | T10Y2Y | < 0 = Recession signal |
| **VIX** | VIXCLS | > 25 = High fear |
| **Fed Funds Rate** | FEDFUNDS | Rising = Tightening |

#### Derived Features

```python
# Yield curve inversion (recession predictor)
yield_curve_inverted = (T10Y2Y < 0).astype(int)

# VIX regime classification
# 0: Low (<15), 1: Normal (15-25), 2: High (25-35), 3: Extreme (>35)
vix_regime = pd.cut(VIXCLS, bins=[0, 15, 25, 35, inf])

# Fed policy direction
fed_hiking = (fed_rate_change > 0).astype(int)
fed_cutting = (fed_rate_change < 0).astype(int)
```

---

### 3.3 NLP Sentiment Analyzer (`naturalLanguageProcessing/`)

**Purpose**: Extract market sentiment from financial news and reports.

#### Pipeline

```
Raw Text â†’ FinBERT â†’ Sentiment Score [-1, +1]
                           â”‚
                           â–¼
              Aggregated Sentiment Vector
              (per stock, per day)
```

---

### 3.4 PPO Agent (`backtesting/`)

**Purpose**: Make portfolio allocation decisions based on the super-state.

#### Environment Interface

```python
class PortfolioEnv:
    # State: [market_data, forecast_vector, sentiment, macro_vector]
    # Action: portfolio weights [wâ‚, wâ‚‚, ..., wâ‚™] where Î£wáµ¢ = 1
    # Reward: Sharpe Ratio of portfolio returns
```

#### Reward Function

```
Reward = (Râ‚š - Râ‚‘) / Ïƒâ‚š   (Sharpe Ratio)

Where:
  Râ‚š = Portfolio return
  Râ‚‘ = Risk-free rate
  Ïƒâ‚š = Portfolio volatility
```

---

## 4. Data Flow

### 4.1 Training Pipeline

```
Step 1: Data Extraction
    bloomberg_prices.csv â”€â”€â”€â”€â”€â”
    nasdaq100_prices.csv â”€â”€â”€â”€â”€â”¼â”€â”€â–º build_deepar_dataset.py
                              â”‚
                              â–¼
                     deepar_dataset.csv
                     (15,669 samples, 9 stocks)

Step 2: Model Training
    deepar_dataset.csv â”€â”€â–º train_deepar.py
                                  â”‚
                                  â–¼
                     checkpoints/deepar/
                     â”œâ”€â”€ deepar_best.pt
                     â”œâ”€â”€ deepar_final.pt
                     â””â”€â”€ training_summary.json

Step 3: Integration (Future)
    Trained DeepAR â”€â”€â”
    FinBERT        â”€â”€â”¼â”€â”€â–º PPO Agent Training
    FRED Data      â”€â”€â”˜
```

### 4.2 Inference Pipeline (Future)

```
Live Data â”€â”€â–º Preprocessor â”€â”€â–º DeepAR   â”€â”€â”
                              FinBERT  â”€â”€â”¼â”€â”€â–º PPO â”€â”€â–º Trade Execution
                              FRED     â”€â”€â”˜
```

---

## 5. Directory Structure

```
Portfolio-Optimizer/
â”‚
â”œâ”€â”€ ğŸ“ data/                          # Data storage
â”‚   â”œâ”€â”€ bloomberg_prices.csv          # Raw Bloomberg price data
â”‚   â”œâ”€â”€ nasdaq100_prices.csv          # NASDAQ-100 constituents
â”‚   â”œâ”€â”€ sp500_prices.csv              # S&P 500 constituents
â”‚   â”œâ”€â”€ nasdaq100_static.csv          # Static features (sector, beta)
â”‚   â””â”€â”€ deepar_dataset.csv            # Processed training data
â”‚
â”œâ”€â”€ ğŸ“ deepAR/                        # DeepAR forecasting module
â”‚   â”œâ”€â”€ model.py                      # DeepARModel architecture
â”‚   â”œâ”€â”€ train_deepar.py               # Training pipeline
â”‚   â”œâ”€â”€ preprocessing.py              # Data utilities
â”‚   â””â”€â”€ bloomberg-data-extraction/    # Data extraction scripts
â”‚       â”œâ”€â”€ build_deepar_dataset.py   # Feature engineering
â”‚       â”œâ”€â”€ download_nasdaq100_data.py
â”‚       â”œâ”€â”€ download_sp500_data.py
â”‚       â””â”€â”€ documentation.md
â”‚
â”œâ”€â”€ ğŸ“ fred_data_extraction/          # FRED macro data module
â”‚   â””â”€â”€ fred_data.py                  # FRED API integration
â”‚
â”œâ”€â”€ ğŸ“ naturalLanguageProcessing/     # NLP sentiment module
â”‚   â””â”€â”€ (FinBERT implementation)
â”‚
â”œâ”€â”€ ğŸ“ backtesting/                   # RL environment & backtesting
â”‚   â””â”€â”€ core/
â”‚       â””â”€â”€ PortfolioEnv.py           # Gym environment
â”‚
â”œâ”€â”€ ğŸ“ checkpoints/                   # Saved model weights
â”‚   â””â”€â”€ deepar/
â”‚       â”œâ”€â”€ deepar_best.pt            # Best validation model
â”‚       â”œâ”€â”€ deepar_final.pt           # Final epoch model
â”‚       â””â”€â”€ training_summary.json     # Metrics & config
â”‚
â”œâ”€â”€ ğŸ“ docs/                          # Documentation
â”‚   â””â”€â”€ ARCHITECTURE.md               # This file
â”‚
â”œâ”€â”€ main.py                           # Entry point
â”œâ”€â”€ pyproject.toml                    # Dependencies
â””â”€â”€ README.md                         # Quick start guide
```

---

## 6. Training Pipeline

### 6.1 DeepAR Training Steps

```bash
# Step 1: Prepare dataset (combines Bloomberg + NASDAQ-100)
python deepAR/bloomberg-data-extraction/build_deepar_dataset.py

# Step 2: Train the model
uv run python deepAR/train_deepar.py --data data/deepar_dataset.csv --epochs 30

# Step 3: Check results
cat checkpoints/deepar/training_summary.json
```

### 6.2 Understanding Training Output

```
Epoch   1/30 | Train Loss: -1.67 | Val Loss: -2.23 | LR: 1.00e-03
              â†‘                    â†‘                  â†‘
              â”‚                    â”‚                  â””â”€ Learning rate
              â”‚                    â””â”€ Validation loss (more negative = better)
              â””â”€ Training loss (more negative = better)
```

**For Gaussian NLL loss:**
- More negative = Model assigns higher probability to correct values
- Less negative = Worse predictions

### 6.3 Evaluation Metrics

| Metric | Description | Good Values |
|--------|-------------|-------------|
| **MAE** | Mean Absolute Error | < 0.02 |
| **RMSE** | Root Mean Squared Error | < 0.03 |
| **Coverage 95%** | % of true values in 95% CI | ~0.95 |
| **CRPS** | Probabilistic accuracy | < 1.0 |

---

## 7. Configuration

### 7.1 Environment Variables

```bash
# .env file
FRED_API_KEY=your_fred_api_key_here
```

### 7.2 Model Hyperparameters

Edit in `deepAR/train_deepar.py`:

```python
DEFAULT_CONFIG = {
    # Architecture
    "hidden_size": 64,       # Increase for more capacity
    "num_layers": 2,         # More layers = deeper model
    "dropout": 0.1,          # Regularization strength
    
    # Training
    "batch_size": 64,        # Larger = faster but more memory
    "learning_rate": 1e-3,   # Lower for fine-tuning
    "patience": 10,          # Early stopping threshold
    
    # Data windows
    "context_length": 60,    # Days of history to use
    "prediction_length": 5,  # Days to forecast
}
```

---

## 8. Future Roadmap

### Phase 1: DeepAR (âœ… Complete)
- [x] Data extraction pipeline
- [x] Feature engineering
- [x] Model architecture
- [x] Training pipeline
- [x] Evaluation metrics

### Phase 2: FRED Integration (ğŸ”„ In Progress)
- [x] FRED API wrapper
- [ ] Macro regime detection
- [ ] Integration with PPO state

### Phase 3: NLP Sentiment (ğŸ“‹ Planned)
- [ ] FinBERT integration
- [ ] News data pipeline
- [ ] Sentiment aggregation

### Phase 4: PPO Agent (ğŸ“‹ Planned)
- [ ] Super-state construction
- [ ] PPO training with ReST methodology
- [ ] Backtesting framework

### Phase 5: Production (ğŸ“‹ Planned)
- [ ] Live data feeds
- [ ] Paper trading
- [ ] Dashboard/monitoring

---

## ğŸ“š References

1. **DeepAR**: Salinas et al., "DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks"
2. **PPO**: Schulman et al., "Proximal Policy Optimization Algorithms"
3. **ReST**: Gulcehre et al., "Reinforced Self-Training (ReST) for Language Modeling"
4. **FinBERT**: Araci, "FinBERT: Financial Sentiment Analysis with Pre-trained Language Models"

---

*Last Updated: January 2026*
